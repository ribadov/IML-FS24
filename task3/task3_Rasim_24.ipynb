{"cells":[{"cell_type":"markdown","id":"f16163d2dd773fbc","metadata":{"collapsed":false,"id":"f16163d2dd773fbc"},"source":["# Task 3\n","This serves as a template which will guide you through the implementation of this task. It is advised to first read the whole template and get a sense of the overall structure of the code before trying to fill in any of the TODO gaps.\n","This is the jupyter notebook version of the template. For the python file version, please refer to the file `template_solution.py`."]},{"cell_type":"markdown","id":"c95f1a3a9db8e3f9","metadata":{"collapsed":false,"id":"c95f1a3a9db8e3f9"},"source":["First, we import necessary libraries:"]},{"cell_type":"code","execution_count":1,"id":"824a840beb8b323e","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2318,"status":"ok","timestamp":1715106542452,"user":{"displayName":"R. I.","userId":"10462238401396752465"},"user_tz":-120},"id":"824a840beb8b323e","outputId":"499b418e-fed6-4e1a-d732-764691896eb4"},"outputs":[],"source":["import numpy as np\n","from torchvision import transforms\n","from torch.utils.data import DataLoader, TensorDataset\n","import os\n","import torch\n","from torchvision import transforms\n","import torchvision.datasets as datasets\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchvision.models import resnet50, ResNet50_Weights\n","from torch.optim import Adam\n","import torch.optim.lr_scheduler as lr_scheduler"]},{"cell_type":"code","execution_count":2,"id":"82adb41ca8c23be6","metadata":{"executionInfo":{"elapsed":267,"status":"ok","timestamp":1715106543602,"user":{"displayName":"R. I.","userId":"10462238401396752465"},"user_tz":-120},"id":"82adb41ca8c23be6"},"outputs":[],"source":["# The device is automatically set to GPU if available, otherwise CPU\n","# If you want to force the device to CPU, you can change the line to\n","# device = torch.device(\"cpu\")\n","# When using the GPU, it is important that your model and all data are on the\n","# same device.\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","global_batch_size = 128\n","global_num_workers = 16"]},{"cell_type":"code","execution_count":3,"id":"oLnMlVt-2nYQ","metadata":{"executionInfo":{"elapsed":387,"status":"ok","timestamp":1715110873928,"user":{"displayName":"R. I.","userId":"10462238401396752465"},"user_tz":-120},"id":"oLnMlVt-2nYQ"},"outputs":[],"source":["def generate_embeddings():\n","  train_transforms = transforms.Compose([\n","      transforms.ToTensor(),\n","      transforms.Resize(256),\n","      transforms.CenterCrop(224),\n","      transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n","  train_dataset = datasets.ImageFolder(root=\"dataset/\", transform=train_transforms)\n","  train_loader = DataLoader(dataset=train_dataset,\n","                          batch_size=50,\n","                          shuffle=False,\n","                          num_workers=8)\n","  model = resnet50(weights=ResNet50_Weights.DEFAULT)\n","  model.eval()\n","\n","  for param in model.parameters():\n","    param.requires_grad = False\n","\n","  model.fc = nn.Sequential()\n","  embeddings = []\n","  for features, labels in train_loader:\n","    embeddings.append(model(features).T.numpy())\n","\n","  np.save('embeddings.npy', embeddings)"]},{"cell_type":"code","execution_count":4,"id":"335d91cc379d4f6b","metadata":{"executionInfo":{"elapsed":280,"status":"ok","timestamp":1715110957337,"user":{"displayName":"R. I.","userId":"10462238401396752465"},"user_tz":-120},"id":"335d91cc379d4f6b"},"outputs":[],"source":["def get_data(file, train=True):\n","    triplets = []\n","    with open(file) as f:\n","        for line in f:\n","            triplets.append(line)\n","\n","    # generate training data from triplets\n","    train_dataset = datasets.ImageFolder(root=\"dataset/\", transform=None)\n","    #filenames = [s[0].split('/')[-1].replace('.jpg', '') for s in train_dataset.samples]\n","    filenames = [s[0].split('/')[-1].replace('.jpg', '').replace('food\\\\', '') for s in train_dataset.samples]\n","\n","    #embeddings = np.load('embeddings3.npy')\n","    # TODO: Normalize the embeddings\n","    embeddings = np.load('embeddings.npy')\n","    #embeddings /= np.linalg.norm(embeddings, axis=1, keepdims=True)\n","    embeddings = np.swapaxes(embeddings, 1, 2)\n","    file_to_embedding = {}\n","    for i in range(200):\n","        for j in range(50):\n","            file_to_embedding[filenames[j+i*50]] = embeddings[i][j]\n","    X = []\n","    y = []\n","    for t in triplets:\n","        emb = [file_to_embedding[a] for a in t.split()]\n","        X.append(np.hstack([emb[0], emb[1], emb[2]]))\n","        y.append([[1]])\n","        if train:\n","            X.append(np.hstack([emb[0], emb[2], emb[1]]))\n","            y.append([[0]])\n","    X = np.vstack(X)\n","    y = np.hstack(y).T\n","    return X, y"]},{"cell_type":"markdown","id":"abc48f07a1c0c478","metadata":{"collapsed":false,"id":"abc48f07a1c0c478"},"source":["Hint: adjust batch_size and num_workers to your PC configuration, so that you don't run out of memory (VRAM if on GPU, RAM if on CPU)"]},{"cell_type":"code","execution_count":7,"id":"6daf836a4adb0abe","metadata":{"executionInfo":{"elapsed":384,"status":"ok","timestamp":1715110958556,"user":{"displayName":"R. I.","userId":"10462238401396752465"},"user_tz":-120},"id":"6daf836a4adb0abe"},"outputs":[],"source":["def create_loader_from_np(X, y=None, train=True, batch_size=16, shuffle=True, num_workers=8):\n","    if train:\n","        dataset = TensorDataset(torch.from_numpy(X).type(torch.float),\n","                                torch.from_numpy(y).type(torch.float))\n","    else:\n","        \"\"\"if y is not None:\n","            dataset = TensorDataset(torch.from_numpy(X).type(torch.float),\n","                                    torch.from_numpy(y).type(torch.long))\n","        else:\"\"\"\n","        dataset = TensorDataset(torch.from_numpy(X).type(torch.float))\n","    loader = DataLoader(dataset=dataset,\n","                        batch_size=batch_size,\n","                        shuffle=shuffle,\n","                        pin_memory=True, num_workers=num_workers)\n","    return loader\n"]},{"cell_type":"markdown","id":"e1baa5918f11a049","metadata":{"collapsed":false,"id":"e1baa5918f11a049"},"source":["TODO: define a model. Here, the basic structure is defined, but you need to fill in the details"]},{"cell_type":"code","execution_count":16,"id":"fcd11318eb7b9488","metadata":{"executionInfo":{"elapsed":380,"status":"ok","timestamp":1715110964838,"user":{"displayName":"R. I.","userId":"10462238401396752465"},"user_tz":-120},"id":"fcd11318eb7b9488"},"outputs":[],"source":["class Net(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.fc1 = nn.Linear(6144, 128)\n","        self.fc2 = nn.Linear(128, 32)\n","        self.fc3 = nn.Linear(32, 16)\n","        self.fc4 = nn.Linear(16, 8)\n","        self.fc5 = nn.Linear(8, 1)\n","\n","    def forward(self, x):\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        x = F.relu(self.fc3(x))\n","        x = F.relu(self.fc4(x))\n","        x = self.fc5(x)\n","        return x"]},{"cell_type":"code","execution_count":17,"id":"Zf7xNjrltkQI","metadata":{"executionInfo":{"elapsed":260,"status":"ok","timestamp":1715111015942,"user":{"displayName":"R. I.","userId":"10462238401396752465"},"user_tz":-120},"id":"Zf7xNjrltkQI"},"outputs":[],"source":["def test_model(model, test_loader):\n","    model.eval()\n","    predictions = []\n","    with torch.no_grad():\n","      for [X] in test_loader:\n","        predicted = model(X)\n","        predicted[predicted >= 0.5] = 1\n","        predicted[predicted < 0.5] = 0\n","        predictions.append(predicted)\n","      predictions = np.vstack(predictions)\n","    np.savetxt(\"results_task3_24.txt\", predictions, fmt='%i')"]},{"cell_type":"code","execution_count":18,"id":"a9j3xdJOvHEK","metadata":{"executionInfo":{"elapsed":276,"status":"ok","timestamp":1715111017471,"user":{"displayName":"R. I.","userId":"10462238401396752465"},"user_tz":-120},"id":"a9j3xdJOvHEK"},"outputs":[],"source":["def train_model(train_loader):\n","    model = Net()\n","    n_epochs = 5\n","    criterion = nn.MSELoss()\n","    optimizer = optim.SGD(model.parameters(), lr=0.01)\n","    scheduler = lr_scheduler.LinearLR(optimizer, start_factor=1.0, end_factor=0.7, total_iters=n_epochs)\n","    \n","    for epoch in range(n_epochs):\n","      running_loss = 0.0      \n","      for i, [X, y] in enumerate(train_loader):\n","        optimizer.zero_grad()\n","        output = model(X)\n","        loss = criterion(output, y)\n","        loss.backward()\n","        optimizer.step()\n","        running_loss += loss.item()\n","      scheduler.step()\n","    return model"]},{"cell_type":"code","execution_count":19,"id":"PF3VlxCrhxoT","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":438},"executionInfo":{"elapsed":20076,"status":"error","timestamp":1715111041533,"user":{"displayName":"R. I.","userId":"10462238401396752465"},"user_tz":-120},"id":"PF3VlxCrhxoT","outputId":"4968d57f-6ea9-4a0b-ad2c-28f7524c1688"},"outputs":[],"source":["# load the training data\n","TRAIN_TRIPLETS = 'train_triplets.txt'\n","TEST_TRIPLETS = 'test_triplets.txt'\n","#generate_embeddings()"]},{"cell_type":"code","execution_count":20,"id":"b2ea99b26c348253","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":418},"executionInfo":{"elapsed":85442,"status":"error","timestamp":1715110051205,"user":{"displayName":"R. I.","userId":"10462238401396752465"},"user_tz":-120},"id":"b2ea99b26c348253","outputId":"5cc715a1-edb3-46da-bf59-2c0d6a7a8536"},"outputs":[],"source":["X, y = get_data(TRAIN_TRIPLETS)\n","# Create data loaders for the training data\n","train_loader = create_loader_from_np(X, y, train = True, batch_size=128)\n","# delete the loaded training data to save memory, as the data loader copies\n","del X\n","del y\n","\n","# repeat for testing data\n","X_test, y_test = get_data(TEST_TRIPLETS, train=False)\n","test_loader = create_loader_from_np(X_test, train = False, batch_size=2048, shuffle=False)\n","del X_test\n","del y_test\n","\n","# define a model and train it\n","model = train_model(train_loader)\n","\n","# test the model on the test data\n","test_model(model, test_loader)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.6"}},"nbformat":4,"nbformat_minor":5}
