{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57002395eb6b50f8",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Task 4\n",
    "This serves as a template which will guide you through the implementation of this task. It is advised to first read the whole template and get a sense of the overall structure of the code before trying to fill in any of the TODO gaps.\n",
    "This is the jupyter notebook version of the template. For the python file version, please refer to the file `template_solution.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a46aca0e5d9ef",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "First, we import necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1c6ff7632991155",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adete\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\adete\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "from transformers import Trainer, TrainingArguments, AdamW \n",
    "from sklearn.metrics import mean_squared_error as mse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5cba49",
   "metadata": {},
   "source": [
    "Depending on your approach, you might need to adapt the structure of this template or parts not marked by TODOs.\n",
    "It is not necessary to completely follow this template. Feel free to add more code and delete any parts that are not required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d9b5e89d4b3a02",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(torch.cuda.is_available())\n",
    "BATCH_SIZE = 4  # TODO: Set the batch size according to both training performance and available memory\n",
    "NUM_EPOCHS = 5 # TODO: Set the number of epochs\n",
    "\n",
    "train_val = pd.read_csv(\"train.csv\")\n",
    "test_val = pd.read_csv(\"test_no_score.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38201f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def print_gpu_info():\n",
    "#     if torch.cuda.is_available():\n",
    "#         device_count = torch.cuda.device_count()\n",
    "#         print(f\"Number of available GPUs: {device_count}\")\n",
    "#         for i in range(device_count):\n",
    "#             device_name = torch.cuda.get_device_name(i)\n",
    "#             device = torch.device(f'cuda:{i}')\n",
    "#             print(f\"GPU {i}: {device_name}\")\n",
    "#         # Print the GPU that is currently in use\n",
    "#         current_device = torch.cuda.current_device()\n",
    "#         print(f\"Current GPU: {torch.cuda.get_device_name(current_device)}\")\n",
    "#     else:\n",
    "#         print(\"CUDA is not available. No GPU found.\")\n",
    "\n",
    "# # Call the function to print GPU info\n",
    "# print_gpu_info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "161fdafaedaa5b0",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ReviewDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_len):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        title = str(self.data.loc[idx, 'title'])\n",
    "        sentence = str(self.data.loc[idx, 'sentence'])\n",
    "        score = self.data.loc[idx].get('score',0.0)\n",
    "\n",
    "        inputs = self.tokenizer(title, sentence, return_tensors=\"pt\", padding = \"max_length\", truncation = True, max_length = self.max_len)\n",
    "        \n",
    "\n",
    "        input_ids = inputs['input_ids'].squeeze()\n",
    "        attention_mask = inputs['attention_mask'].squeeze()\n",
    "     \n",
    "        return {\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask': attention_mask,\n",
    "            'score': torch.tensor(score, dtype=torch.float)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "676f7a012f50e988",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\adete\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "max_len = 512  # Adjust\n",
    "\n",
    "train_dataset = ReviewDataset(train_val, tokenizer, max_len)\n",
    "test_dataset = ReviewDataset(test_val, tokenizer, max_len)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=True, num_workers=0, pin_memory=True)\n",
    "test_loader = DataLoader(dataset=test_dataset,\n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         shuffle=False, num_workers=0, pin_memory=True)\n",
    "# Additional code if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "843f38b9dbea00b0",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MyModule(nn.Module):\n",
    "    \n",
    "    def __init__(self, premodel):\n",
    "        super().__init__()\n",
    "        self.premodel = premodel\n",
    "        self.fc1 = nn.Linear(self.premodel.config.hidden_size,1)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.premodel(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        x = self.dropout(outputs.last_hidden_state[:,0])\n",
    "        score = self.fc1(x)\n",
    "\n",
    "        return score.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605e5bd0373a1dda",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "premodel = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "model = MyModule(premodel)\n",
    "model.load_state_dict(torch.load(\"Das_Model_ceci.pth\"))\n",
    "model.to(DEVICE)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=5e-6)\n",
    "criterion = nn.MSELoss()\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    \n",
    "    vloss = 0.0\n",
    "    print('Epoch :', epoch+1, '/',NUM_EPOCHS)\n",
    "    \n",
    "    for batch in tqdm(train_loader, total=len(train_loader)):\n",
    "        model.train()\n",
    "        ids = batch['input_ids']\n",
    "        attention_mask = batch['attention_mask']\n",
    "        score = batch['score']\n",
    "        ids, attention_mask, score = ids.to(DEVICE), attention_mask.to(DEVICE), score.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        train_scores = model(input_ids = ids, attention_mask=attention_mask)\n",
    "        loss = criterion(train_scores, score)\n",
    "        vloss += loss.item()\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    scheduler.step()\n",
    "    print(f\"Epoch {epoch+1}, Training Loss: {vloss / len(train_loader)}\")\n",
    "\n",
    "model.eval()\n",
    "vloss = 0.0\n",
    "predictions = []\n",
    "actuals = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    results = []\n",
    "    \n",
    "    for batch in tqdm(test_loader, total=len(test_loader)):\n",
    "\n",
    "        ids = batch['input_ids'].to(DEVICE)\n",
    "        attention_mask = batch['attention_mask'].to(DEVICE)\n",
    "        \n",
    "        outputs = model(ids,attention_mask)\n",
    "        \n",
    "        predictions.extend(outputs.cpu().numpy())\n",
    "    \n",
    "    with open(\"result1.txt\", \"w\") as f:\n",
    "        for val in predictions:\n",
    "            f.write(f\"{val}\\n\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "852e22b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model's state dictionary\n",
    "torch.save(model.state_dict(), \"Das_Model_Ceci.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
